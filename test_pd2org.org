#+AUTHOR: Altynbek Isabekov
#+EMAIL: aisabekov@ku.edu.tr
#+LANGUAGE: en
#+PROPERTY: header-args:emacs-lisp :results silent
#+OPTIONS: ^:nil
#+OPTIONS: html-style:nil
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
#+HTML_HEAD: <script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
* To convert Pandas dataframe to tabular format using tabulate()
#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+begin_src python :results output raw
  import pandas as pd
  df = pd.DataFrame({
      "a": [1,2,3],
      "b": [4,5,6]
  })
  df_str = tabulate(df, headers=df.columns, tablefmt="orgtbl", showindex=False)
  print(df_str)
#+end_src

#+RESULTS:
| a | b |
|---+---|
| 1 | 4 |
| 2 | 5 |
| 3 | 6 |

* To convert Pandas dataframe to tabular format using pd2org()
#+name: pd2org
#+begin_src python :var df="df" :exports none :session none
  return f"return tabulate({df}, headers={df}.columns, tablefmt='orgtbl', showindex=False)"
#+end_src

#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+begin_src python :results value raw :noweb strip-export :session none
  import pandas as pd
  df = pd.DataFrame({
      "a": [1,2,3],
      "b": [4,5,6]
  })
  <<pd2org("df")>>
#+end_src

#+RESULTS:
| a | b |
|---+---|
| 1 | 4 |
| 2 | 5 |
| 3 | 6 |

* To convert PySpark dataframe to tabular format using ps2org()
#+name: ps2org
#+header: :noweb strip-export
#+begin_src python :var df_in="df_in" :exports none :session none :results value raw
  return f"return {df_in}.toPandas().to_markdown(index=False, tablefmt='orgtbl')"
#+end_src

#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+BEGIN_SRC python :var df="df" :results value raw
  import pyspark.sql.functions as F
  import pyspark.sql.types as T
  from pyspark.sql.window import Window
  from pyspark.sql import SparkSession
  spark = SparkSession.builder.master("local").appName("test-app").getOrCreate()
  schema = T.StructType(
      [
          T.StructField("a", T.IntegerType(), True),
          T.StructField("b", T.IntegerType(), True),
      ]
  )
  data = [(1, 4), (2, 5), (3, 6)]
  df = spark.createDataFrame(schema=schema, data=data)
  <<ps2org("df")>>
#+END_SRC

#+RESULTS:
| a | b |
|---+---|
| 1 | 4 |
| 2 | 5 |
| 3 | 6 |

* To convert PySpark dataframe to tabular format using show2org() hidden
#+name: show2org
#+begin_src python :var df_in="df_in" :exports none :results value raw :session none
  return f"print({df_in}.toPandas().to_markdown(index=False, tablefmt='orgtbl'))#"
#+end_src

#+RESULTS: show2org

#+NAME: nostderr
#+BEGIN_SRC python :var spark="spark" :exports none :results value raw
  return "spark.sparkContext.setLogLevel('OFF')"
#+END_SRC

#+RESULTS: nostderr
spark.sparkContext.setLogLevel('OFF')

#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+BEGIN_SRC python :results output raw  :exports both :session test-run10
  import pyspark.sql.functions as F
  import pyspark.sql.types as T
  from pyspark.sql.window import Window
  from pyspark.sql import SparkSession
  spark = SparkSession.builder.config("spark.log.level", "OFF").master("local").appName("test-app").getOrCreate()
  <<nostderr("spark")>>
  schema = T.StructType(
      [
          T.StructField("a", T.IntegerType(), True),
          T.StructField("b", T.IntegerType(), True),
      ]
  )
  data = [(1, 4), (2, 5), (3, 6)]
  df = spark.createDataFrame(schema=schema, data=data)
  print("Dataframe df:")
  <<show2org("df")>>df.show()
#+END_SRC

#+RESULTS:
|   a |   b |
|-----+-----|
|   1 |   4 |
|   2 |   5 |
|   3 |   6 |

Which is converted into the following code block during evaluation:
#+BEGIN_SRC python :results output raw  :exports both
  from tabulate import tabulate
  import pyspark.sql.functions as F
  import pyspark.sql.types as T
  from pyspark.sql.window import Window
  from pyspark.sql import SparkSession
  spark = SparkSession.builder.master("local").appName("test-app").getOrCreate()
  schema = T.StructType(
      [
          T.StructField("a", T.IntegerType(), True),
          T.StructField("b", T.IntegerType(), True),
      ]
  )
  data = [(1, 4), (2, 5), (3, 6)]
  df = spark.createDataFrame(schema=schema, data=data)
  print(df.toPandas().to_markdown(index=False, tablefmt='orgtbl'))#df.show()
#+END_SRC
